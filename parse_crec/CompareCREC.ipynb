{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e52856d",
   "metadata": {},
   "source": [
    "# Compare speeches from old dataset and new CREC dataset\n",
    "\n",
    "This script will iterate over the days in 2015, and try to match speeches between the old dataset and new dataset\n",
    "\n",
    "Matching speeches proceeds in the following way. We first process the speech in the following way:\n",
    "* We only keep speeches from House and Senate\n",
    "* We only keep speeches where the speaker name starts with \"Dr.\", \"Mr.\", \"Ms.\", \"Mrs.\", \"Miss\". This eliminates speeches from the \"The speaker\", \"The clerk\", etc., which are mostly procedural in nature and very inconsistent / hard to compare\n",
    "* We throw out speeches that are very short (these also tend to be procedural), of 1500 characters or less\n",
    "* From the remaining speeches, we remove all punctuation.\n",
    "\n",
    "Of the remaining and cleaned speeches, we say that an old and a new speech match if their \"edit distance\" (also called Levenshtein distance) is 20 or less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, json, pprint, re\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from config import DATA_DIR, DATA_DIR_DOWNLOADS\n",
    "\n",
    "# Define some utilities for cleaning text\n",
    "def remove_extra_spaces(s):\n",
    "    while '  ' in s:\n",
    "        s = s.replace('  ',' ')\n",
    "    return s.strip()\n",
    "\n",
    "def remove_punct(s): # removes punctuations\n",
    "    s = s.replace(\".\", \" \")\n",
    "    s = s.replace(\",\", \" \")\n",
    "    s = s.replace(\"'\", \"\")\n",
    "    s = s.replace('\"', \" \")\n",
    "    s = s.replace('-', \"\")\n",
    "    s = s.replace('`', \"\")\n",
    "    s = s.replace(';', \" \")\n",
    "    s = s.replace('*', \" \")\n",
    "    s = s.replace('~', \" \")\n",
    "    s = s.replace('_', \" \")\n",
    "    s = s.replace('\\\\', \"\")\n",
    "    s = s.replace('โข', \" \")\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    "def stripspeech(s):\n",
    "    # Clean up and standardize the speech a bit\n",
    "    s = s.replace('ยง', 'sec')\n",
    "    s = remove_extra_spaces(remove_punct(s).lower())\n",
    "    s = s.replace(' ', '')\n",
    "    s = s.replace('9111', '911')\n",
    "    s = s.replace('9/11', '911')\n",
    "    return s\n",
    "\n",
    "\n",
    "# We will compare speeches in old and dataset and new dataset using the \n",
    "# \"edlib\" (edit distance library)\n",
    "import edlib\n",
    "\n",
    "def match_speeches(a,b, verbose=False):\n",
    "    match1 = { rndx1 : None for rndx1, r1 in a.iterrows() }\n",
    "    match2 = { rndx2 : None for rndx2, r2 in b.iterrows() }\n",
    "\n",
    "    def distance_func(r1,r2): \n",
    "        return edlib.align(stripspeech(r1.speech), stripspeech(r2.speech))['editDistance']\n",
    "\n",
    "    for rndx1, r1 in a.iterrows():\n",
    "        for rndx2, r2 in b.iterrows():\n",
    "            d=distance_func(r1,r2)\n",
    "            if d<20:\n",
    "                match1[rndx1]=rndx2\n",
    "                match2[rndx2]=rndx1\n",
    "                break\n",
    "\n",
    "    if verbose:\n",
    "        for rndx1, r1 in a.iterrows():\n",
    "            if match1[rndx1] is None:\n",
    "                print('No match to speech in old dataset')\n",
    "                print(r1)\n",
    "                print()\n",
    "\n",
    "        for rndx2, r2 in b.iterrows():\n",
    "            if match2[rndx2] is None:\n",
    "                print('No match to speech in new dataset')\n",
    "                print(r2)\n",
    "                print()\n",
    "    return match1, match2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4741411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new speeches data from CREC\n",
    "df_new=pd.read_hdf(DATA_DIR_DOWNLOADS+'/crec2015to2021.hdf')  \n",
    "\n",
    "# Load old speeches data from 114th congress\n",
    "df_old=pd.read_csv(DATA_DIR +'/created_data/daily_114.csv',sep='\\t', index_col='speech_id')\n",
    "\n",
    "# Restrict attention to house and senate speeches\n",
    "df_old=df_old.loc[df_old.chamber.isin(['H','S'])]\n",
    "# Drop speeches where the speaker is \"The speaker\", \"The clerk\", etc.\n",
    "# These are very incosistent and hard to compare\n",
    "valid_speakers = ['mr. ','ms. ','mrs.', 'dr. ','miss'] \n",
    "df_old=df_old[df_old.speaker.str.lower().str[0:4].isin(valid_speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0e21c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that we are not missing speeches in new data\n",
    "def short_filter(s):  # Remove very short speeches, as these are inconsistent\n",
    "    return len(stripspeech(s))>=1500\n",
    "\n",
    "tot_days = 0\n",
    "tot_old  = 0\n",
    "tot_new  = 0\n",
    "tot_old_success = 0\n",
    "tot_new_success = 0\n",
    "\n",
    "for unique_date in sorted(set(df_old.date)):\n",
    "    c_old = df_old[df_old.date==unique_date]\n",
    "    c_old = c_old[c_old.speech.apply(short_filter)]\n",
    "    c_new = df_new[df_new.date==unique_date]\n",
    "    c_new = c_new[c_new.speech.apply(short_filter)]\n",
    "    \n",
    "    other_msg = \"\"\n",
    "    \n",
    "    num_old = len(c_old)\n",
    "    num_new = len(c_new)\n",
    "    \n",
    "    if num_old > num_new: # on this day,  more speeches in old data than new data\n",
    "        other_msg = '(old data has more speeches: %d vs %d' % (num_old, num_new)\n",
    "        \n",
    "    match_old, match_new = match_speeches(c_old, c_new)\n",
    "    # Calculate percentage of speeches in old dataset that match to a new speech\n",
    "    \n",
    "\n",
    "    success_old = len([v for v in match_old.values() if v is not None])\n",
    "    success_new = len([v for v in match_new.values() if v is not None])\n",
    "    \n",
    "    p_old, p_new = '---', '---'\n",
    "    if num_old: p_old = \"%3d\" % (100*success_old/num_old)\n",
    "    if num_new: p_new = \"%3d\" % (100*success_new/num_new)\n",
    "    print(unique_date, 'old->new: %s%% (%4d/%4d), new->old: %s%% (%4d/%4d) %s' % \n",
    "          (p_old, success_old, num_old, p_new, success_new, num_new, other_msg))\n",
    "\n",
    "    tot_days += 1\n",
    "    tot_old  += num_old\n",
    "    tot_new  += num_new\n",
    "    tot_old_success += success_old\n",
    "    tot_new_success += success_new\n",
    "    \n",
    "\n",
    "p_old, p_new = '---', '---'\n",
    "if tot_old: p_old = \"%3d\" % (100*tot_old_success/tot_old)\n",
    "if tot_new: p_new = \"%3d\" % (100*tot_new_success/tot_new)\n",
    "    \n",
    "print('----------')\n",
    "print('TOTAL %3dd old->new: %s%% (%4d/%4d), new->old: %s%% (%4d/%4d)' % \n",
    "      (tot_days, p_old, tot_old_success, tot_old, p_new, tot_new_success, tot_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9eb2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
